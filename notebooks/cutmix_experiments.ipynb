{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import ssl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from fun.models import *\n",
    "sns.set_style(\"whitegrid\")\n",
    "import pandas as pd\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x27682a06e70>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "\n",
    "train_ds = torchvision.datasets.CIFAR10(\n",
    "    root=\"../data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform_train\n",
    "\n",
    ")\n",
    "\n",
    "test_ds = torchvision.datasets.CIFAR10(\n",
    "    root=\"../data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform_test\n",
    ")\n",
    "\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(dataset_augm):\n",
    "    figure = plt.figure(figsize=(8, 8))\n",
    "    cols, rows = 3, 3\n",
    "    for i in range(1, cols * rows + 1):\n",
    "        sample_idx = torch.randint(len(dataset_augm), size=(1,)).item()\n",
    "        img = dataset_augm[sample_idx]\n",
    "        figure.add_subplot(rows, cols, i)\n",
    "        plt.axis(\"off\")\n",
    "        img = img.cpu()\n",
    "        img = img.numpy()\n",
    "        img = np.transpose(img, (1, 2, 0))\n",
    "        plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = int(W * cut_rat)\n",
    "    cut_h = int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer, beta, cutmix_prob):\n",
    "\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "\n",
    "    model.train()\n",
    "    train_loss, correct = 0, 0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # generate mixed sample\n",
    "        r = np.random.rand(1)\n",
    "        if beta > 0 and r < cutmix_prob:\n",
    "            lam = np.random.beta(beta, beta)\n",
    "            rand_index = torch.randperm(X.size()[0]).cuda()\n",
    "            target_a = y\n",
    "            target_b = y[rand_index]\n",
    "            bbx1, bby1, bbx2, bby2 = rand_bbox(X.size(), lam)\n",
    "            X[:, :, bbx1:bbx2, bby1:bby2] = X[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "            # adjust lambda to exactly match pixel ratio\n",
    "            lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (X.size()[-1] * X.size()[-2]))\n",
    "            \n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred, target_a) * lam + loss_fn(pred, target_b) * (1. - lam)\n",
    "\n",
    "        else:\n",
    "            # compute output\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred, y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    train_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\" Train Accuracy: {(100*correct):>0.1f}%, Train Avg loss {train_loss:>8f} \\n\")\n",
    "    return correct, train_loss\n",
    "\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "\n",
    "    print(f\"Test Accuracy: {(100*correct):>0.1f}%, Test Avg loss: {test_loss:>8f} \\n\")\n",
    "    return correct, test_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      " Train Accuracy: 31.5%, Train Avg loss 1.920662 \n",
      "\n",
      "Test Accuracy: 44.9%, Test Avg loss: 1.528286 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      " Train Accuracy: 41.8%, Train Avg loss 1.664022 \n",
      "\n",
      "Test Accuracy: 55.3%, Test Avg loss: 1.278952 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      " Train Accuracy: 48.3%, Train Avg loss 1.521697 \n",
      "\n",
      "Test Accuracy: 61.8%, Test Avg loss: 1.113334 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      " Train Accuracy: 51.6%, Train Avg loss 1.442360 \n",
      "\n",
      "Test Accuracy: 64.4%, Test Avg loss: 1.043148 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      " Train Accuracy: 53.9%, Train Avg loss 1.396427 \n",
      "\n",
      "Test Accuracy: 65.3%, Test Avg loss: 1.008953 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      " Train Accuracy: 55.5%, Train Avg loss 1.351085 \n",
      "\n",
      "Test Accuracy: 66.5%, Test Avg loss: 0.965935 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      " Train Accuracy: 56.3%, Train Avg loss 1.327347 \n",
      "\n",
      "Test Accuracy: 67.7%, Test Avg loss: 0.952980 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      " Train Accuracy: 57.9%, Train Avg loss 1.292441 \n",
      "\n",
      "Test Accuracy: 70.2%, Test Avg loss: 0.888002 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      " Train Accuracy: 58.8%, Train Avg loss 1.276339 \n",
      "\n",
      "Test Accuracy: 69.9%, Test Avg loss: 0.884743 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      " Train Accuracy: 59.1%, Train Avg loss 1.262139 \n",
      "\n",
      "Test Accuracy: 71.0%, Test Avg loss: 0.870452 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      " Train Accuracy: 59.8%, Train Avg loss 1.248538 \n",
      "\n",
      "Test Accuracy: 70.7%, Test Avg loss: 0.872611 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      " Train Accuracy: 60.5%, Train Avg loss 1.223802 \n",
      "\n",
      "Test Accuracy: 70.8%, Test Avg loss: 0.855007 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      " Train Accuracy: 60.6%, Train Avg loss 1.225077 \n",
      "\n",
      "Test Accuracy: 73.4%, Test Avg loss: 0.790022 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      " Train Accuracy: 61.5%, Train Avg loss 1.206703 \n",
      "\n",
      "Test Accuracy: 74.7%, Test Avg loss: 0.765460 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      " Train Accuracy: 61.5%, Train Avg loss 1.197060 \n",
      "\n",
      "Test Accuracy: 73.8%, Test Avg loss: 0.786119 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      " Train Accuracy: 62.0%, Train Avg loss 1.196104 \n",
      "\n",
      "Test Accuracy: 75.3%, Test Avg loss: 0.749579 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      " Train Accuracy: 62.3%, Train Avg loss 1.181766 \n",
      "\n",
      "Test Accuracy: 75.5%, Test Avg loss: 0.745137 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      " Train Accuracy: 62.8%, Train Avg loss 1.171471 \n",
      "\n",
      "Test Accuracy: 76.4%, Test Avg loss: 0.714764 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      " Train Accuracy: 63.0%, Train Avg loss 1.159632 \n",
      "\n",
      "Test Accuracy: 75.8%, Test Avg loss: 0.730834 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      " Train Accuracy: 63.8%, Train Avg loss 1.152358 \n",
      "\n",
      "Test Accuracy: 75.8%, Test Avg loss: 0.722279 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      " Train Accuracy: 63.3%, Train Avg loss 1.161415 \n",
      "\n",
      "Test Accuracy: 76.7%, Test Avg loss: 0.708719 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      " Train Accuracy: 64.2%, Train Avg loss 1.145248 \n",
      "\n",
      "Test Accuracy: 76.4%, Test Avg loss: 0.714199 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      " Train Accuracy: 63.7%, Train Avg loss 1.147380 \n",
      "\n",
      "Test Accuracy: 76.4%, Test Avg loss: 0.708451 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      " Train Accuracy: 64.2%, Train Avg loss 1.139890 \n",
      "\n",
      "Test Accuracy: 76.4%, Test Avg loss: 0.699120 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      " Train Accuracy: 64.4%, Train Avg loss 1.136439 \n",
      "\n",
      "Test Accuracy: 77.2%, Test Avg loss: 0.684795 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      " Train Accuracy: 64.9%, Train Avg loss 1.117934 \n",
      "\n",
      "Test Accuracy: 76.2%, Test Avg loss: 0.706623 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      " Train Accuracy: 64.6%, Train Avg loss 1.123452 \n",
      "\n",
      "Test Accuracy: 77.3%, Test Avg loss: 0.680853 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      " Train Accuracy: 65.1%, Train Avg loss 1.112054 \n",
      "\n",
      "Test Accuracy: 76.2%, Test Avg loss: 0.701896 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      " Train Accuracy: 65.8%, Train Avg loss 1.108101 \n",
      "\n",
      "Test Accuracy: 77.2%, Test Avg loss: 0.685460 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      " Train Accuracy: 65.8%, Train Avg loss 1.096984 \n",
      "\n",
      "Test Accuracy: 77.9%, Test Avg loss: 0.668991 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      " Train Accuracy: 65.6%, Train Avg loss 1.104882 \n",
      "\n",
      "Test Accuracy: 77.8%, Test Avg loss: 0.674197 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      " Train Accuracy: 65.3%, Train Avg loss 1.104023 \n",
      "\n",
      "Test Accuracy: 77.5%, Test Avg loss: 0.686877 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      " Train Accuracy: 65.9%, Train Avg loss 1.092299 \n",
      "\n",
      "Test Accuracy: 77.9%, Test Avg loss: 0.665131 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      " Train Accuracy: 66.2%, Train Avg loss 1.084129 \n",
      "\n",
      "Test Accuracy: 78.1%, Test Avg loss: 0.661329 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      " Train Accuracy: 66.7%, Train Avg loss 1.077209 \n",
      "\n",
      "Test Accuracy: 78.5%, Test Avg loss: 0.649244 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      " Train Accuracy: 66.4%, Train Avg loss 1.073798 \n",
      "\n",
      "Test Accuracy: 78.8%, Test Avg loss: 0.641935 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      " Train Accuracy: 66.7%, Train Avg loss 1.070691 \n",
      "\n",
      "Test Accuracy: 78.9%, Test Avg loss: 0.645394 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      " Train Accuracy: 66.3%, Train Avg loss 1.080821 \n",
      "\n",
      "Test Accuracy: 78.0%, Test Avg loss: 0.664046 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      " Train Accuracy: 66.7%, Train Avg loss 1.075644 \n",
      "\n",
      "Test Accuracy: 79.2%, Test Avg loss: 0.621277 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      " Train Accuracy: 67.2%, Train Avg loss 1.068499 \n",
      "\n",
      "Test Accuracy: 79.1%, Test Avg loss: 0.628685 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      " Train Accuracy: 67.3%, Train Avg loss 1.059298 \n",
      "\n",
      "Test Accuracy: 79.0%, Test Avg loss: 0.640740 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      " Train Accuracy: 67.9%, Train Avg loss 1.045044 \n",
      "\n",
      "Test Accuracy: 79.2%, Test Avg loss: 0.630637 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      " Train Accuracy: 67.7%, Train Avg loss 1.051653 \n",
      "\n",
      "Test Accuracy: 78.5%, Test Avg loss: 0.643804 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      " Train Accuracy: 67.2%, Train Avg loss 1.057951 \n",
      "\n",
      "Test Accuracy: 78.8%, Test Avg loss: 0.634343 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      " Train Accuracy: 68.2%, Train Avg loss 1.036009 \n",
      "\n",
      "Test Accuracy: 79.9%, Test Avg loss: 0.617339 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      " Train Accuracy: 67.8%, Train Avg loss 1.044361 \n",
      "\n",
      "Test Accuracy: 78.5%, Test Avg loss: 0.652372 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      " Train Accuracy: 67.3%, Train Avg loss 1.054599 \n",
      "\n",
      "Test Accuracy: 79.5%, Test Avg loss: 0.623268 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      " Train Accuracy: 68.1%, Train Avg loss 1.035458 \n",
      "\n",
      "Test Accuracy: 79.2%, Test Avg loss: 0.632371 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      " Train Accuracy: 67.8%, Train Avg loss 1.049699 \n",
      "\n",
      "Test Accuracy: 79.2%, Test Avg loss: 0.637370 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      " Train Accuracy: 67.7%, Train Avg loss 1.052632 \n",
      "\n",
      "Test Accuracy: 79.8%, Test Avg loss: 0.610829 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      " Train Accuracy: 68.2%, Train Avg loss 1.034120 \n",
      "\n",
      "Test Accuracy: 79.2%, Test Avg loss: 0.629702 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      " Train Accuracy: 68.3%, Train Avg loss 1.039825 \n",
      "\n",
      "Test Accuracy: 79.4%, Test Avg loss: 0.631903 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      " Train Accuracy: 68.5%, Train Avg loss 1.025202 \n",
      "\n",
      "Test Accuracy: 79.7%, Test Avg loss: 0.617057 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      " Train Accuracy: 68.0%, Train Avg loss 1.032364 \n",
      "\n",
      "Test Accuracy: 79.5%, Test Avg loss: 0.627850 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      " Train Accuracy: 69.0%, Train Avg loss 1.014127 \n",
      "\n",
      "Test Accuracy: 79.7%, Test Avg loss: 0.605995 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      " Train Accuracy: 68.8%, Train Avg loss 1.022386 \n",
      "\n",
      "Test Accuracy: 79.5%, Test Avg loss: 0.612811 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      " Train Accuracy: 69.3%, Train Avg loss 1.010830 \n",
      "\n",
      "Test Accuracy: 80.0%, Test Avg loss: 0.615510 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      " Train Accuracy: 68.9%, Train Avg loss 1.020634 \n",
      "\n",
      "Test Accuracy: 80.3%, Test Avg loss: 0.607127 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      " Train Accuracy: 69.1%, Train Avg loss 1.010633 \n",
      "\n",
      "Test Accuracy: 80.0%, Test Avg loss: 0.612378 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      " Train Accuracy: 68.5%, Train Avg loss 1.021888 \n",
      "\n",
      "Test Accuracy: 80.5%, Test Avg loss: 0.592053 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "batch_size = 8\n",
    "epochs = 60\n",
    "beta = 1\n",
    "cutmix_prob = 0.6\n",
    "\n",
    "\n",
    "data = np.array([[0]*4]*epochs)\n",
    "bnet_SGD_augm_history = pd.DataFrame(data, columns = [\"test_acc\", \"train_acc\", \"test_loss\", \"train_loss\"])\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=batch_size, \n",
    "        shuffle=True\n",
    "        )\n",
    "test_dataloader = DataLoader(\n",
    "    test_ds, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    "    )\n",
    "\n",
    "net = Net_dropout_new(dropout_rate=0.1).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "\n",
    "for t in range(epochs):\n",
    "\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_acc, train_loss = train(train_dataloader, net, criterion, optimizer, beta, cutmix_prob)\n",
    "    test_acc, test_loss = test(test_dataloader, net, criterion)\n",
    "\n",
    "    bnet_SGD_augm_history.loc[t,\"train_acc\"] = train_acc        \n",
    "    bnet_SGD_augm_history.loc[t,\"test_acc\"] = test_acc\n",
    "    bnet_SGD_augm_history.loc[t,\"train_loss\"] = train_loss\n",
    "    bnet_SGD_augm_history.loc[t,\"test_loss\"] = test_loss\n",
    "        \n",
    "bnet_SGD_augm_history.to_csv(r\"..\\bnet_augm_history.csv\")\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4a164a018fc136c3d2d029afb355fec41d76b984f2d1aac3c4a34f0b10311231"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
