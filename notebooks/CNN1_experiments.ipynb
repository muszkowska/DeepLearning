{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import ssl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from fun.models import *\n",
    "sns.set_style(\"whitegrid\")\n",
    "from torch.utils.data import random_split\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssl._create_default_https_context = ssl._create_unverified_context\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataset and split into valid-train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_ds = torchvision.datasets.CIFAR10(\n",
    "    root=\"../data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    "\n",
    ")\n",
    "\n",
    "test_ds = torchvision.datasets.CIFAR10(\n",
    "    root=\"../data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.train()\n",
    "    train_loss, correct = 0, 0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    train_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\" Train Accuracy: {(100*correct):>0.1f}%, Train Avg loss {train_loss:>8f} \\n\")\n",
    "    return correct, train_loss\n",
    "\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "\n",
    "    print(f\"Test Accuracy: {(100*correct):>0.1f}%, Test Avg loss: {test_loss:>8f} \\n\")\n",
    "    return correct, test_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------\n",
    "#--------------------- DO PUSZCZENIA ------------------------------\n",
    "#------------------------------------------------------------------\n",
    "learning_rates = [1e-6, 1e-5,1e-4,1e-3,0.01, 0.1]\n",
    "batch_size = 4\n",
    "epochs = 25\n",
    "data = np.array([[0]*len(learning_rates)]*epochs)\n",
    "lr_train_acc_history = pd.DataFrame(data, columns = learning_rates)\n",
    "lr_test_acc_history = pd.DataFrame(data, columns = learning_rates)\n",
    "lr_train_loss_history  = pd.DataFrame(data, columns = learning_rates)\n",
    "lr_test_loss_history  = pd.DataFrame(data, columns = learning_rates)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=batch_size, \n",
    "        shuffle=True\n",
    "        )\n",
    "test_dataloader = DataLoader(\n",
    "    valid_ds, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    "    )\n",
    "\n",
    "net = Net().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for lr in learning_rates:\n",
    "    print(f\"Learning Rate: {lr}\\n********************************\")\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "\n",
    "    for t in range(epochs):\n",
    "\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train_acc, train_loss = train(train_dataloader, net, criterion, optimizer)\n",
    "        test_acc, test_loss = test(test_dataloader, net, criterion)\n",
    "        lr_train_acc_history.loc[t,lr] = train_acc        \n",
    "        lr_test_acc_history.loc[t,lr] = test_acc\n",
    "        lr_train_loss_history.loc[t,lr] = train_loss\n",
    "        lr_test_loss_history.loc[t,lr] = test_loss\n",
    "\n",
    "lr_train_acc_history.to_csv(\"../data/results/lr_train_acc_history.csv\")\n",
    "lr_train_acc_history.to_csv(\"../data/results/lr_train_acc_history.csv\")\n",
    "lr_train_loss_history.to_csv(\"../data/results/lr_train_loss_history.csv\")\n",
    "lr_test_loss_history.to_csv(\"../data/results/lr_test_loss_history.csv\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch size experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------\n",
    "#--------------------- DO PUSZCZENIA ------------------------------\n",
    "#------------------------------------------------------------------\n",
    "epochs = 25\n",
    "batch_sizes = [2,4,8,16,32]\n",
    "lr = 1e-3\n",
    "data = np.array([[0]*len(batch_sizes)]*epochs)\n",
    "batch_train_acc_history = pd.DataFrame(data, columns = batch_sizes)\n",
    "batch_test_acc_history = pd.DataFrame(data, columns = batch_sizes)\n",
    "batch_train_loss_history  = pd.DataFrame(data, columns = batch_sizes)\n",
    "batch_test_loss_history  = pd.DataFrame(data, columns = batch_sizes)\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    print(f\"Batch size: {batch_size} \\n\")\n",
    "    \n",
    "    train_dataloader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=batch_size, \n",
    "        shuffle=True\n",
    "        )\n",
    "    test_dataloader = DataLoader(\n",
    "        valid_ds, \n",
    "        batch_size=batch_size,\n",
    "        shuffle=False\n",
    "        )\n",
    "\n",
    "    net = Net().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "    max_accuracy_in_batch=0\n",
    "    epoch = 1\n",
    "    for t in range(epochs):\n",
    "\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train_acc, train_loss = train(train_dataloader, net, criterion, optimizer)\n",
    "        test_acc, test_loss = test(test_dataloader, net, criterion)\n",
    "        batch_train_acc_history.loc[t,batch_size] = train_acc        \n",
    "        batch_test_acc_history.loc[t,batch_size] = test_acc\n",
    "        batch_train_loss_history.loc[t,batch_size] = train_loss\n",
    "        batch_test_loss_history.loc[t,batch_size] = test_loss\n",
    "\n",
    "batch_train_acc_history.to_csv(\"../data/results/batch_train_acc_history.csv\")\n",
    "batch_test_acc_history.to_csv(\"../data/results/batch_test_acc_history.csv\")\n",
    "batch_train_loss_history.to_csv(\"../data/results/batch_train_loss_history.csv\")\n",
    "batch_test_loss_history.to_csv(\"../data/results/batch_test_loss_history.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------\n",
    "#--------------------- DO PUSZCZENIA ------------------------------\n",
    "#------------------------------------------------------------------\n",
    "batch_size = 4\n",
    "epochs = 20\n",
    "learning_rate = 1e-3\n",
    "dropouts = [0.1, 0.2, 0.25, 0.35, 0.5]\n",
    "data = np.array([[0]*len(dropouts)]*epochs)\n",
    "dropouts_train_acc_history = pd.DataFrame(data, columns = dropouts)\n",
    "dropouts_test_acc_history = pd.DataFrame(data, columns = dropouts)\n",
    "dropouts_train_loss_history  = pd.DataFrame(data, columns = dropouts)\n",
    "dropouts_test_loss_history  = pd.DataFrame(data, columns = dropouts)\n",
    "train_dataloader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=batch_size, \n",
    "        shuffle=True\n",
    "        )\n",
    "test_dataloader = DataLoader(\n",
    "    valid_ds, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    "    )\n",
    "\n",
    "for drop_out in dropouts:\n",
    "\n",
    "    print(f\"Dropout {drop_out}\\n-------------------------------\")\n",
    "    net = Net_dropout(dropout_rate=drop_out).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate)\n",
    "\n",
    "    for t in range(epochs):\n",
    "        \n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train_acc, train_loss = train(train_dataloader, net, criterion, optimizer)\n",
    "        test_acc, test_loss = test(test_dataloader, net, criterion)\n",
    "        dropouts_train_acc_history.loc[t,drop_out] = train_acc        \n",
    "        dropouts_train_acc_history.loc[t,drop_out] = test_acc\n",
    "        dropouts_train_loss_history.loc[t,drop_out] = train_loss\n",
    "        dropouts_test_loss_history.loc[t,drop_out] = test_loss\n",
    "\n",
    "dropouts_train_acc_history.to_csv(\"../data/results/dropouts_train_acc_history.csv\")    \n",
    "dropouts_train_acc_history.to_csv(\"../data/results/dropouts_train_acc_history.csv\")\n",
    "dropouts_train_loss_history.to_csv(\"../data/results/dropouts_train_loss_history.csv\")\n",
    "dropouts_test_loss_history.to_csv(\"../data/results/dropouts_test_loss_history.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final with dropout small "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------\n",
    "#--------------------- DO PUSZCZENIA ------------------------------\n",
    "#------------------------------------------------------------------\n",
    "batch_size = 4\n",
    "epochs = 20\n",
    "learning_rate = 1e-3\n",
    "dropout_rate = 0.25\n",
    "\n",
    "data = np.array([[0]*4]*epochs)\n",
    "dropouts_train_test_final = pd.DataFrame(data, columns = [\"test_acc\", \"train_acc\", \"test_loss\", \"train_loss\"])\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=batch_size, \n",
    "        shuffle=True\n",
    "        )\n",
    "test_dataloader = DataLoader(\n",
    "    valid_ds, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    "    )\n",
    "\n",
    "\n",
    "net = Net_dropout(dropout_rate=dropout_rate).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate)\n",
    "\n",
    "for t in range(epochs):\n",
    "    \n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_acc, train_loss = train(train_dataloader, net, criterion, optimizer)\n",
    "    test_acc, test_loss = test(test_dataloader, net, criterion)\n",
    "    dropouts_train_test_final.loc[t,\"test_acc\"] = test_acc\n",
    "    dropouts_train_test_final.loc[t,\"train_acc\"] = train_acc\n",
    "    dropouts_train_test_final.loc[t,\"test_loss\"] = test_loss\n",
    "    dropouts_train_test_final.loc[t,\"train_loss\"] = train_loss\n",
    "\n",
    "dropouts_train_test_final.to_csv(\"../data/results/dropouts_train_test_final.csv\")\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final with dropdown bigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------\n",
    "#--------------------- DO PUSZCZENIA ------------------------------\n",
    "#------------------------------------------------------------------\n",
    "batch_size = 4\n",
    "epochs = 20\n",
    "learning_rate = 1e-3\n",
    "dropout_rate = 0.25\n",
    "\n",
    "data = np.array([[0]*4]*epochs)\n",
    "dropouts_bigger_train_test_final = pd.DataFrame(data, columns = [\"test_acc\", \"train_acc\", \"test_loss\", \"train_loss\"])\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=batch_size, \n",
    "        shuffle=True\n",
    "        )\n",
    "test_dataloader = DataLoader(\n",
    "    valid_ds, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    "    )\n",
    "\n",
    "\n",
    "net = Net_dropout_new(dropout_rate=dropout_rate).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate)\n",
    "\n",
    "for t in range(epochs):\n",
    "    \n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    tr_acc, tr_loss = train(train_dataloader, net, criterion, optimizer)\n",
    "    test_acc, test_loss = test(test_dataloader, net, criterion)\n",
    "    dropouts_bigger_train_test_final.loc[t,\"test_acc\"] = test_acc\n",
    "    dropouts_bigger_train_test_final.loc[t,\"train_acc\"] = train_acc\n",
    "    dropouts_bigger_train_test_final.loc[t,\"test_loss\"] = test_loss\n",
    "    dropouts_bigger_train_test_final.loc[t,\"train_loss\"] = train_loss\n",
    "\n",
    "dropouts_bigger_train_test_final.to_csv(\"../data/results/dropouts_bigger_train_test_final.csv\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WEIGHT DECAY - ADAMW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 8 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      " Train Accuracy: 50.9%, Train Avg loss 1.366056 \n",
      "\n",
      "Test Accuracy: 59.0%, Test Avg loss: 1.140588 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      " Train Accuracy: 62.3%, Train Avg loss 1.068926 \n",
      "\n",
      "Test Accuracy: 63.5%, Test Avg loss: 1.032446 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      " Train Accuracy: 66.2%, Train Avg loss 0.960117 \n",
      "\n",
      "Test Accuracy: 64.4%, Test Avg loss: 1.022269 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      " Train Accuracy: 68.9%, Train Avg loss 0.888816 \n",
      "\n",
      "Test Accuracy: 64.9%, Test Avg loss: 1.007903 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      " Train Accuracy: 70.8%, Train Avg loss 0.833821 \n",
      "\n",
      "Test Accuracy: 67.2%, Test Avg loss: 0.949934 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      " Train Accuracy: 72.0%, Train Avg loss 0.792762 \n",
      "\n",
      "Test Accuracy: 67.4%, Test Avg loss: 0.930169 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      " Train Accuracy: 73.4%, Train Avg loss 0.753727 \n",
      "\n",
      "Test Accuracy: 67.9%, Test Avg loss: 0.936816 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      " Train Accuracy: 74.6%, Train Avg loss 0.722960 \n",
      "\n",
      "Test Accuracy: 68.0%, Test Avg loss: 0.938747 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      " Train Accuracy: 75.4%, Train Avg loss 0.693542 \n",
      "\n",
      "Test Accuracy: 68.5%, Test Avg loss: 0.946307 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      " Train Accuracy: 76.3%, Train Avg loss 0.667172 \n",
      "\n",
      "Test Accuracy: 69.5%, Test Avg loss: 0.917921 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      " Train Accuracy: 77.2%, Train Avg loss 0.642567 \n",
      "\n",
      "Test Accuracy: 68.5%, Test Avg loss: 0.949322 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      " Train Accuracy: 77.9%, Train Avg loss 0.619302 \n",
      "\n",
      "Test Accuracy: 67.9%, Test Avg loss: 0.994649 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      " Train Accuracy: 78.6%, Train Avg loss 0.600250 \n",
      "\n",
      "Test Accuracy: 68.2%, Test Avg loss: 0.979770 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      " Train Accuracy: 79.3%, Train Avg loss 0.584354 \n",
      "\n",
      "Test Accuracy: 68.2%, Test Avg loss: 1.000240 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      " Train Accuracy: 80.0%, Train Avg loss 0.563769 \n",
      "\n",
      "Test Accuracy: 66.1%, Test Avg loss: 1.134590 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      " Train Accuracy: 80.7%, Train Avg loss 0.542868 \n",
      "\n",
      "Test Accuracy: 67.8%, Test Avg loss: 1.041560 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      " Train Accuracy: 81.2%, Train Avg loss 0.528385 \n",
      "\n",
      "Test Accuracy: 68.3%, Test Avg loss: 1.033494 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      " Train Accuracy: 81.7%, Train Avg loss 0.515334 \n",
      "\n",
      "Test Accuracy: 67.7%, Test Avg loss: 1.075313 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      " Train Accuracy: 82.3%, Train Avg loss 0.497642 \n",
      "\n",
      "Test Accuracy: 67.4%, Test Avg loss: 1.094731 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      " Train Accuracy: 82.8%, Train Avg loss 0.479265 \n",
      "\n",
      "Test Accuracy: 68.2%, Test Avg loss: 1.104205 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      " Train Accuracy: 83.4%, Train Avg loss 0.464827 \n",
      "\n",
      "Test Accuracy: 67.2%, Test Avg loss: 1.163030 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      " Train Accuracy: 83.6%, Train Avg loss 0.455530 \n",
      "\n",
      "Test Accuracy: 66.6%, Test Avg loss: 1.190243 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      " Train Accuracy: 84.3%, Train Avg loss 0.439766 \n",
      "\n",
      "Test Accuracy: 67.8%, Test Avg loss: 1.219225 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      " Train Accuracy: 84.7%, Train Avg loss 0.424429 \n",
      "\n",
      "Test Accuracy: 66.6%, Test Avg loss: 1.250445 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      " Train Accuracy: 85.2%, Train Avg loss 0.416787 \n",
      "\n",
      "Test Accuracy: 67.2%, Test Avg loss: 1.220187 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      " Train Accuracy: 85.3%, Train Avg loss 0.407303 \n",
      "\n",
      "Test Accuracy: 66.9%, Test Avg loss: 1.186389 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      " Train Accuracy: 85.9%, Train Avg loss 0.391892 \n",
      "\n",
      "Test Accuracy: 66.5%, Test Avg loss: 1.338064 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      " Train Accuracy: 86.2%, Train Avg loss 0.384445 \n",
      "\n",
      "Test Accuracy: 67.3%, Test Avg loss: 1.257286 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      " Train Accuracy: 86.5%, Train Avg loss 0.378575 \n",
      "\n",
      "Test Accuracy: 67.1%, Test Avg loss: 1.312844 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      " Train Accuracy: 87.0%, Train Avg loss 0.366900 \n",
      "\n",
      "Test Accuracy: 66.5%, Test Avg loss: 1.341537 \n",
      "\n",
      "Batch size: 8 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      " Train Accuracy: 50.1%, Train Avg loss 1.397287 \n",
      "\n",
      "Test Accuracy: 55.8%, Test Avg loss: 1.252410 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      " Train Accuracy: 60.8%, Train Avg loss 1.109269 \n",
      "\n",
      "Test Accuracy: 58.1%, Test Avg loss: 1.177891 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      " Train Accuracy: 64.7%, Train Avg loss 1.004812 \n",
      "\n",
      "Test Accuracy: 65.0%, Test Avg loss: 1.000872 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      " Train Accuracy: 67.3%, Train Avg loss 0.931540 \n",
      "\n",
      "Test Accuracy: 64.5%, Test Avg loss: 1.032868 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      " Train Accuracy: 68.9%, Train Avg loss 0.881053 \n",
      "\n",
      "Test Accuracy: 67.5%, Test Avg loss: 0.945815 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      " Train Accuracy: 70.4%, Train Avg loss 0.841460 \n",
      "\n",
      "Test Accuracy: 67.3%, Test Avg loss: 0.962761 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      " Train Accuracy: 71.5%, Train Avg loss 0.809943 \n",
      "\n",
      "Test Accuracy: 67.6%, Test Avg loss: 0.943196 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      " Train Accuracy: 72.7%, Train Avg loss 0.779196 \n",
      "\n",
      "Test Accuracy: 67.4%, Test Avg loss: 0.951771 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      " Train Accuracy: 73.4%, Train Avg loss 0.761172 \n",
      "\n",
      "Test Accuracy: 60.4%, Test Avg loss: 1.181498 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      " Train Accuracy: 73.8%, Train Avg loss 0.741286 \n",
      "\n",
      "Test Accuracy: 68.3%, Test Avg loss: 0.942042 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      " Train Accuracy: 74.3%, Train Avg loss 0.722553 \n",
      "\n",
      "Test Accuracy: 67.8%, Test Avg loss: 0.968641 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      " Train Accuracy: 74.8%, Train Avg loss 0.709741 \n",
      "\n",
      "Test Accuracy: 67.3%, Test Avg loss: 0.995391 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      " Train Accuracy: 75.4%, Train Avg loss 0.690051 \n",
      "\n",
      "Test Accuracy: 67.3%, Test Avg loss: 0.989523 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      " Train Accuracy: 76.2%, Train Avg loss 0.673516 \n",
      "\n",
      "Test Accuracy: 67.5%, Test Avg loss: 0.975528 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      " Train Accuracy: 76.5%, Train Avg loss 0.661729 \n",
      "\n",
      "Test Accuracy: 69.7%, Test Avg loss: 0.916981 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      " Train Accuracy: 76.8%, Train Avg loss 0.651894 \n",
      "\n",
      "Test Accuracy: 66.2%, Test Avg loss: 1.022136 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      " Train Accuracy: 77.1%, Train Avg loss 0.643981 \n",
      "\n",
      "Test Accuracy: 68.6%, Test Avg loss: 0.957547 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      " Train Accuracy: 77.4%, Train Avg loss 0.632219 \n",
      "\n",
      "Test Accuracy: 67.1%, Test Avg loss: 0.985865 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      " Train Accuracy: 77.7%, Train Avg loss 0.624776 \n",
      "\n",
      "Test Accuracy: 67.8%, Test Avg loss: 0.968731 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      " Train Accuracy: 78.0%, Train Avg loss 0.616440 \n",
      "\n",
      "Test Accuracy: 67.5%, Test Avg loss: 1.022032 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      " Train Accuracy: 78.5%, Train Avg loss 0.611918 \n",
      "\n",
      "Test Accuracy: 67.9%, Test Avg loss: 0.988769 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      " Train Accuracy: 78.6%, Train Avg loss 0.602284 \n",
      "\n",
      "Test Accuracy: 68.0%, Test Avg loss: 0.984785 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      " Train Accuracy: 79.1%, Train Avg loss 0.592653 \n",
      "\n",
      "Test Accuracy: 67.7%, Test Avg loss: 1.030211 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      " Train Accuracy: 79.1%, Train Avg loss 0.586576 \n",
      "\n",
      "Test Accuracy: 64.6%, Test Avg loss: 1.106292 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      " Train Accuracy: 79.5%, Train Avg loss 0.578979 \n",
      "\n",
      "Test Accuracy: 68.6%, Test Avg loss: 0.970273 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      " Train Accuracy: 79.2%, Train Avg loss 0.580253 \n",
      "\n",
      "Test Accuracy: 67.9%, Test Avg loss: 0.997491 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      " Train Accuracy: 79.7%, Train Avg loss 0.571848 \n",
      "\n",
      "Test Accuracy: 68.8%, Test Avg loss: 0.983779 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      " Train Accuracy: 79.8%, Train Avg loss 0.567596 \n",
      "\n",
      "Test Accuracy: 67.3%, Test Avg loss: 1.017530 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      " Train Accuracy: 80.2%, Train Avg loss 0.562362 \n",
      "\n",
      "Test Accuracy: 67.7%, Test Avg loss: 1.029108 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      " Train Accuracy: 80.4%, Train Avg loss 0.556794 \n",
      "\n",
      "Test Accuracy: 67.7%, Test Avg loss: 1.012168 \n",
      "\n",
      "Batch size: 8 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      " Train Accuracy: 49.4%, Train Avg loss 1.404839 \n",
      "\n",
      "Test Accuracy: 57.4%, Test Avg loss: 1.201376 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      " Train Accuracy: 59.6%, Train Avg loss 1.148388 \n",
      "\n",
      "Test Accuracy: 61.2%, Test Avg loss: 1.095373 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      " Train Accuracy: 61.9%, Train Avg loss 1.087120 \n",
      "\n",
      "Test Accuracy: 60.2%, Test Avg loss: 1.126176 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      " Train Accuracy: 63.4%, Train Avg loss 1.056662 \n",
      "\n",
      "Test Accuracy: 61.8%, Test Avg loss: 1.078307 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      " Train Accuracy: 63.7%, Train Avg loss 1.039080 \n",
      "\n",
      "Test Accuracy: 61.8%, Test Avg loss: 1.093277 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      " Train Accuracy: 63.8%, Train Avg loss 1.037759 \n",
      "\n",
      "Test Accuracy: 58.3%, Test Avg loss: 1.210932 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      " Train Accuracy: 64.2%, Train Avg loss 1.027420 \n",
      "\n",
      "Test Accuracy: 61.5%, Test Avg loss: 1.091432 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      " Train Accuracy: 64.3%, Train Avg loss 1.020260 \n",
      "\n",
      "Test Accuracy: 59.4%, Test Avg loss: 1.150802 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      " Train Accuracy: 64.4%, Train Avg loss 1.022444 \n",
      "\n",
      "Test Accuracy: 58.1%, Test Avg loss: 1.150544 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      " Train Accuracy: 64.6%, Train Avg loss 1.014871 \n",
      "\n",
      "Test Accuracy: 62.0%, Test Avg loss: 1.084389 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      " Train Accuracy: 64.6%, Train Avg loss 1.013251 \n",
      "\n",
      "Test Accuracy: 47.6%, Test Avg loss: 1.454038 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      " Train Accuracy: 65.0%, Train Avg loss 1.002714 \n",
      "\n",
      "Test Accuracy: 58.1%, Test Avg loss: 1.182198 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      " Train Accuracy: 65.0%, Train Avg loss 1.001812 \n",
      "\n",
      "Test Accuracy: 43.5%, Test Avg loss: 1.828690 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      " Train Accuracy: 65.3%, Train Avg loss 0.998176 \n",
      "\n",
      "Test Accuracy: 51.5%, Test Avg loss: 1.445999 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      " Train Accuracy: 65.3%, Train Avg loss 0.995219 \n",
      "\n",
      "Test Accuracy: 56.2%, Test Avg loss: 1.245730 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      " Train Accuracy: 65.5%, Train Avg loss 0.993581 \n",
      "\n",
      "Test Accuracy: 59.0%, Test Avg loss: 1.185050 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      " Train Accuracy: 65.2%, Train Avg loss 0.989734 \n",
      "\n",
      "Test Accuracy: 63.5%, Test Avg loss: 1.044465 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      " Train Accuracy: 65.6%, Train Avg loss 0.989638 \n",
      "\n",
      "Test Accuracy: 62.9%, Test Avg loss: 1.067172 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      " Train Accuracy: 65.8%, Train Avg loss 0.986019 \n",
      "\n",
      "Test Accuracy: 63.2%, Test Avg loss: 1.075953 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      " Train Accuracy: 65.8%, Train Avg loss 0.983786 \n",
      "\n",
      "Test Accuracy: 62.9%, Test Avg loss: 1.067386 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      " Train Accuracy: 65.9%, Train Avg loss 0.985516 \n",
      "\n",
      "Test Accuracy: 56.7%, Test Avg loss: 1.245984 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      " Train Accuracy: 65.9%, Train Avg loss 0.980050 \n",
      "\n",
      "Test Accuracy: 60.7%, Test Avg loss: 1.115804 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      " Train Accuracy: 65.8%, Train Avg loss 0.979700 \n",
      "\n",
      "Test Accuracy: 61.2%, Test Avg loss: 1.140037 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      " Train Accuracy: 66.2%, Train Avg loss 0.976083 \n",
      "\n",
      "Test Accuracy: 62.8%, Test Avg loss: 1.074029 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      " Train Accuracy: 66.0%, Train Avg loss 0.978388 \n",
      "\n",
      "Test Accuracy: 64.1%, Test Avg loss: 1.012060 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      " Train Accuracy: 66.2%, Train Avg loss 0.976968 \n",
      "\n",
      "Test Accuracy: 61.8%, Test Avg loss: 1.097527 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      " Train Accuracy: 66.3%, Train Avg loss 0.976634 \n",
      "\n",
      "Test Accuracy: 55.2%, Test Avg loss: 1.287469 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      " Train Accuracy: 66.1%, Train Avg loss 0.973607 \n",
      "\n",
      "Test Accuracy: 57.8%, Test Avg loss: 1.183193 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      " Train Accuracy: 66.2%, Train Avg loss 0.973338 \n",
      "\n",
      "Test Accuracy: 61.6%, Test Avg loss: 1.102280 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      " Train Accuracy: 65.9%, Train Avg loss 0.974820 \n",
      "\n",
      "Test Accuracy: 62.3%, Test Avg loss: 1.078690 \n",
      "\n",
      "Batch size: 8 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      " Train Accuracy: 47.5%, Train Avg loss 1.457494 \n",
      "\n",
      "Test Accuracy: 54.3%, Test Avg loss: 1.277539 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      " Train Accuracy: 55.6%, Train Avg loss 1.256042 \n",
      "\n",
      "Test Accuracy: 42.8%, Test Avg loss: 1.584042 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      " Train Accuracy: 57.5%, Train Avg loss 1.211607 \n",
      "\n",
      "Test Accuracy: 55.9%, Test Avg loss: 1.216241 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      " Train Accuracy: 58.0%, Train Avg loss 1.193630 \n",
      "\n",
      "Test Accuracy: 56.8%, Test Avg loss: 1.218799 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      " Train Accuracy: 58.5%, Train Avg loss 1.187465 \n",
      "\n",
      "Test Accuracy: 58.6%, Test Avg loss: 1.160703 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      " Train Accuracy: 58.6%, Train Avg loss 1.182822 \n",
      "\n",
      "Test Accuracy: 60.8%, Test Avg loss: 1.135416 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      " Train Accuracy: 58.6%, Train Avg loss 1.182854 \n",
      "\n",
      "Test Accuracy: 55.4%, Test Avg loss: 1.258139 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      " Train Accuracy: 58.5%, Train Avg loss 1.179639 \n",
      "\n",
      "Test Accuracy: 54.3%, Test Avg loss: 1.353887 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      " Train Accuracy: 59.2%, Train Avg loss 1.170316 \n",
      "\n",
      "Test Accuracy: 57.4%, Test Avg loss: 1.243125 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      " Train Accuracy: 59.0%, Train Avg loss 1.168624 \n",
      "\n",
      "Test Accuracy: 58.7%, Test Avg loss: 1.203608 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      " Train Accuracy: 59.1%, Train Avg loss 1.168138 \n",
      "\n",
      "Test Accuracy: 44.9%, Test Avg loss: 1.489419 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      " Train Accuracy: 59.4%, Train Avg loss 1.163003 \n",
      "\n",
      "Test Accuracy: 59.4%, Test Avg loss: 1.180727 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      " Train Accuracy: 59.3%, Train Avg loss 1.162188 \n",
      "\n",
      "Test Accuracy: 49.1%, Test Avg loss: 1.522275 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      " Train Accuracy: 59.2%, Train Avg loss 1.162689 \n",
      "\n",
      "Test Accuracy: 50.7%, Test Avg loss: 1.370697 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      " Train Accuracy: 59.2%, Train Avg loss 1.162984 \n",
      "\n",
      "Test Accuracy: 56.4%, Test Avg loss: 1.226611 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      " Train Accuracy: 59.3%, Train Avg loss 1.166569 \n",
      "\n",
      "Test Accuracy: 49.1%, Test Avg loss: 1.423830 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      " Train Accuracy: 59.4%, Train Avg loss 1.158011 \n",
      "\n",
      "Test Accuracy: 58.7%, Test Avg loss: 1.198008 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      " Train Accuracy: 59.8%, Train Avg loss 1.159336 \n",
      "\n",
      "Test Accuracy: 51.4%, Test Avg loss: 1.358032 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      " Train Accuracy: 59.4%, Train Avg loss 1.165575 \n",
      "\n",
      "Test Accuracy: 41.7%, Test Avg loss: 1.660086 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      " Train Accuracy: 59.2%, Train Avg loss 1.164013 \n",
      "\n",
      "Test Accuracy: 55.7%, Test Avg loss: 1.247888 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      " Train Accuracy: 59.4%, Train Avg loss 1.160229 \n",
      "\n",
      "Test Accuracy: 56.5%, Test Avg loss: 1.211174 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      " Train Accuracy: 59.4%, Train Avg loss 1.159617 \n",
      "\n",
      "Test Accuracy: 59.5%, Test Avg loss: 1.153680 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      " Train Accuracy: 59.3%, Train Avg loss 1.162290 \n",
      "\n",
      "Test Accuracy: 22.8%, Test Avg loss: 3.080306 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      " Train Accuracy: 59.3%, Train Avg loss 1.162709 \n",
      "\n",
      "Test Accuracy: 42.6%, Test Avg loss: 1.654616 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      " Train Accuracy: 59.5%, Train Avg loss 1.158788 \n",
      "\n",
      "Test Accuracy: 53.0%, Test Avg loss: 1.296641 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      " Train Accuracy: 59.6%, Train Avg loss 1.156973 \n",
      "\n",
      "Test Accuracy: 52.8%, Test Avg loss: 1.298586 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      " Train Accuracy: 59.4%, Train Avg loss 1.159049 \n",
      "\n",
      "Test Accuracy: 57.1%, Test Avg loss: 1.228311 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      " Train Accuracy: 59.6%, Train Avg loss 1.153725 \n",
      "\n",
      "Test Accuracy: 56.2%, Test Avg loss: 1.208041 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      " Train Accuracy: 59.3%, Train Avg loss 1.159901 \n",
      "\n",
      "Test Accuracy: 51.7%, Test Avg loss: 1.421247 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      " Train Accuracy: 59.7%, Train Avg loss 1.159019 \n",
      "\n",
      "Test Accuracy: 60.8%, Test Avg loss: 1.163335 \n",
      "\n",
      "Batch size: 8 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      " Train Accuracy: 44.7%, Train Avg loss 1.516783 \n",
      "\n",
      "Test Accuracy: 45.5%, Test Avg loss: 1.552696 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      " Train Accuracy: 51.2%, Train Avg loss 1.378914 \n",
      "\n",
      "Test Accuracy: 53.8%, Test Avg loss: 1.322323 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      " Train Accuracy: 52.0%, Train Avg loss 1.355451 \n",
      "\n",
      "Test Accuracy: 51.4%, Test Avg loss: 1.340211 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      " Train Accuracy: 52.9%, Train Avg loss 1.337998 \n",
      "\n",
      "Test Accuracy: 38.6%, Test Avg loss: 1.716502 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      " Train Accuracy: 53.0%, Train Avg loss 1.337806 \n",
      "\n",
      "Test Accuracy: 48.1%, Test Avg loss: 1.436187 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      " Train Accuracy: 53.2%, Train Avg loss 1.331274 \n",
      "\n",
      "Test Accuracy: 48.4%, Test Avg loss: 1.452811 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      " Train Accuracy: 53.2%, Train Avg loss 1.335672 \n",
      "\n",
      "Test Accuracy: 47.9%, Test Avg loss: 1.422844 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      " Train Accuracy: 53.3%, Train Avg loss 1.335256 \n",
      "\n",
      "Test Accuracy: 48.9%, Test Avg loss: 1.427299 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      " Train Accuracy: 53.3%, Train Avg loss 1.330338 \n",
      "\n",
      "Test Accuracy: 50.2%, Test Avg loss: 1.392293 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      " Train Accuracy: 53.1%, Train Avg loss 1.332774 \n",
      "\n",
      "Test Accuracy: 47.4%, Test Avg loss: 1.454926 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      " Train Accuracy: 53.1%, Train Avg loss 1.334772 \n",
      "\n",
      "Test Accuracy: 36.8%, Test Avg loss: 1.662344 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      " Train Accuracy: 53.1%, Train Avg loss 1.339784 \n",
      "\n",
      "Test Accuracy: 46.5%, Test Avg loss: 1.466104 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      " Train Accuracy: 53.0%, Train Avg loss 1.337393 \n",
      "\n",
      "Test Accuracy: 23.4%, Test Avg loss: 2.376793 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      " Train Accuracy: 53.3%, Train Avg loss 1.332986 \n",
      "\n",
      "Test Accuracy: 49.5%, Test Avg loss: 1.385010 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      " Train Accuracy: 53.2%, Train Avg loss 1.328362 \n",
      "\n",
      "Test Accuracy: 33.0%, Test Avg loss: 1.861080 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      " Train Accuracy: 53.2%, Train Avg loss 1.335079 \n",
      "\n",
      "Test Accuracy: 51.5%, Test Avg loss: 1.360086 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      " Train Accuracy: 53.2%, Train Avg loss 1.332076 \n",
      "\n",
      "Test Accuracy: 47.9%, Test Avg loss: 1.454665 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      " Train Accuracy: 53.2%, Train Avg loss 1.331327 \n",
      "\n",
      "Test Accuracy: 51.3%, Test Avg loss: 1.322847 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      " Train Accuracy: 53.2%, Train Avg loss 1.332296 \n",
      "\n",
      "Test Accuracy: 49.5%, Test Avg loss: 1.436162 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      " Train Accuracy: 53.3%, Train Avg loss 1.333019 \n",
      "\n",
      "Test Accuracy: 51.6%, Test Avg loss: 1.353091 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      " Train Accuracy: 53.2%, Train Avg loss 1.331770 \n",
      "\n",
      "Test Accuracy: 48.5%, Test Avg loss: 1.428664 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      " Train Accuracy: 53.3%, Train Avg loss 1.332774 \n",
      "\n",
      "Test Accuracy: 53.2%, Test Avg loss: 1.324279 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      " Train Accuracy: 53.4%, Train Avg loss 1.333773 \n",
      "\n",
      "Test Accuracy: 50.4%, Test Avg loss: 1.394372 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      " Train Accuracy: 53.4%, Train Avg loss 1.333165 \n",
      "\n",
      "Test Accuracy: 50.1%, Test Avg loss: 1.392972 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      " Train Accuracy: 53.4%, Train Avg loss 1.330073 \n",
      "\n",
      "Test Accuracy: 39.6%, Test Avg loss: 1.695676 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      " Train Accuracy: 53.2%, Train Avg loss 1.333450 \n",
      "\n",
      "Test Accuracy: 41.0%, Test Avg loss: 1.619044 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      " Train Accuracy: 53.4%, Train Avg loss 1.330727 \n",
      "\n",
      "Test Accuracy: 31.9%, Test Avg loss: 1.905145 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      " Train Accuracy: 53.3%, Train Avg loss 1.331286 \n",
      "\n",
      "Test Accuracy: 42.2%, Test Avg loss: 1.575801 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      " Train Accuracy: 53.2%, Train Avg loss 1.337913 \n",
      "\n",
      "Test Accuracy: 51.1%, Test Avg loss: 1.400733 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      " Train Accuracy: 53.0%, Train Avg loss 1.332652 \n",
      "\n",
      "Test Accuracy: 45.4%, Test Avg loss: 1.553779 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------------------------------------\n",
    "#--------------------- DO PUSZCZENIA ------------------------------\n",
    "#------------------------------------------------------------------\n",
    "epochs = 30\n",
    "batch_size = 8\n",
    "weight_decay = [0.001, 0.01, 0.1, 0.25, 0.5]\n",
    "lr = 1e-3\n",
    "data = np.array([[0]*len(weight_decay)]*epochs)\n",
    "wd_train_acc_history = pd.DataFrame(data, columns = weight_decay)\n",
    "wd_test_acc_history = pd.DataFrame(data, columns = weight_decay)\n",
    "wd_train_loss_history  = pd.DataFrame(data, columns = weight_decay)\n",
    "wd_test_loss_history  = pd.DataFrame(data, columns = weight_decay)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=batch_size, \n",
    "    shuffle=True\n",
    "    )\n",
    "test_dataloader = DataLoader(\n",
    "    test_ds, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    "    )\n",
    "\n",
    "for wd in weight_decay:\n",
    "    print(f\"Batch size: {batch_size} \\n\")    \n",
    "    \n",
    "\n",
    "    net = Net().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(net.parameters(), lr=lr, weight_decay=wd)\n",
    "    \n",
    "    for t in range(epochs):\n",
    "\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train_acc, train_loss = train(train_dataloader, net, criterion, optimizer)\n",
    "        test_acc, test_loss = test(test_dataloader, net, criterion)\n",
    "        wd_train_acc_history.loc[t,wd] = train_acc        \n",
    "        wd_test_acc_history.loc[t,wd] = test_acc\n",
    "        wd_train_loss_history.loc[t,wd] = train_loss\n",
    "        wd_test_loss_history.loc[t,wd] = test_loss\n",
    "\n",
    "wd_train_acc_history.to_csv(\"../data/results/bs8_ep30_lr-3_wd/wd_train_acc_history.csv\")\n",
    "\n",
    "wd_test_acc_history.to_csv(\"../data/results/bs8_ep30_lr-3_wd/wd_test_acc_history.csv\")\n",
    "\n",
    "wd_train_loss_history.to_csv(\"../data/results/bs8_ep30_lr-3_wd/wd_train_loss_history.csv\")\n",
    "\n",
    "wd_test_loss_history.to_csv(\"../data/results/bs8_ep30_lr-3_wd/wd_test_loss_history.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7c9f80f3618f45ecfef668bfa3a583f5bb597334d77308f2cc3491cc6d9e9d8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
